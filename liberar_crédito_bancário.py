# -*- coding: utf-8 -*-
"""Crédito bancário.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R2-Hi9SVs3KCHrXQADayw0EsIk8c2vdh

## **Análise** do German Credit Data

[https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)](https://)
"""

# importação dos dados direto do site da UCI
import pandas as pd

url = "http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"

dados = pd.read_csv(url, delimiter = ' ', header = None) #separador é o espaço e não tem cabeçalho 
dados.head()

"""### **Pré processamento inicial**"""

#renomeando as colunas

nomes = ['conta', 'duração', 'historico', 'motivo', 'quantia', 
         'poupança', 'emprego', 'taxa', 'status', 'garantia', 
         'residencia', 'propriedades', 'idade', 'financiamentos', 'moradia', 
         'creditos', 'trabalho', 'dependentes', 'telefone', 'estrangeiro', 'pagador']

dados.columns = nomes #trocando os nomes das colunas pelos respectivos de "nomes"
dados.head()

#Pré-processamento inicial das variáveis

dic = {'A11': 'negativo', 'A12': '[0-200)', 'A13': '200+', 'A14': 'sem conta'}
dados['conta'] = dados['conta'].map(dic)


dic = {'A30': 'primeira vez', 'A31': 'creditos quitados', 'A32': 'pagamento em dia', 
       'A33': 'já atrasou pagamentos', 'A34': 'conta crítica'}
dados['historico'] = dados['historico'].map(dic)


dic = {'A40': 'carro novo', 'A41': 'carro usado', 'A42': 'móveis', 
       'A43': 'radio/televisão', 'A44': 'itens de casa', 'A45': 'reparos', 
       'A46': 'educação', 'A47': 'férias', 'A48': 'retreinamentos', 
       'A49': 'negócios', 'A410': 'outros'}
dados['motivo'] = dados['motivo'].map(dic)


dic = {'A61': '<100', 'A62': '[100-500)', 'A63': '[500-1000)',
       'A64': '>1000', 'A65': 'sem conta'}
dados['poupança'] = dados['poupança'].map(dic)

dic = {'A71': 'desempregado', 'A72': '< 1 ano', 'A73': '[1,4) anos',
       'A74': '[4,7) anos', 'A75': '> 7 anos'}
dados['emprego'] = dados['emprego'].map(dic)


dic = {'A91': 'masculino/divorciado', 'A92': 'feminino/divorciado',
       'A93': 'masculino/solteiro', 'A94': 'masculino/casado'}
dados['status'] = dados['status'].map(dic)


dic = {'A101': 'nenhum', 'A102': 'co-aplicante', 'A103': 'fiador'}
dados['garantia'] = dados['garantia'].map(dic)

 
dic = {'A121': 'imobiliario', 'A122': 'seguro  de vida',
       'A123': 'carro', 'A124': 'sem propriedades'}
dados['propriedades'] = dados['propriedades'].map(dic)


dic = {'A141': 'bancos', 'A142': 'lojas', 'A143': 'nenhum'}
dados['financiamentos'] = dados['financiamentos'].map(dic)


dic = {'A151': 'alugada', 'A152': 'própria', 'A153': 'de graça'}
dados['moradia'] = dados['moradia'].map(dic)


dic = {'A171': 'desempregado', 'A172': 'nível 1', 'A173': 'nível 2', 'A174': 'nível 3'}
dados['trabalho'] = dados['trabalho'].map(dic)


dic = {'A191': 'não', 'A192': 'sim'}
dados['telefone'] = dados['telefone'].map(dic)

dic = {'A201': 'não', 'A202': 'sim'}
dados['estrangeiro'] = dados['estrangeiro'].map(dic)


dic = {1: 'bom', 2: 'mau'}
dados['pagador'] = dados['pagador'].map(dic)

dados.head()

dados.describe() #estatística básica

"""Análise:

Temos 1000 informações, mil linhas de dados
A média de duração dos empréstimos é de 20 meses; sendo o valor médio de 2.973 Euros a uma taxa média de 2.97%; em média os clientes possuem uma residência, 35 anos de idade e 1 dependente. 
O menor empréstimo foi no valor de 250 Euros e o maior de 18424 Euros.
"""

dados.to_csv('german_processado_traduzido.csv', index = False) #exportar os dados corrigidos em csv

"""### **Análise Exploratória dos Dados**"""

# instalando biblioteca de visualização

!pip install sweetviz

import sweetviz as sv

dados['pagador'] = dados['pagador'].map({'bom': 0, 'mau': 1}) 
#transformando as métricas em números (0 e 1)

eda = sv.analyze(source = dados, target_feat = 'pagador') #fonte = dados, variável alvo = pagador
eda.show_notebook() #mostrar o resultado

#biblioteca com modelos prontos

!pip install pycaret

"""
### **Machine Learning com PyCaret**"""

from pycaret.classification import setup, models, create_model, compare_models, tune_model, predict_model, plot_model, predict_model, evaluate_model, finalize_model, save_model

# Help da função Setup
?setup

# Configuração da Modelagem automática feita pelo PyCaret
# Envolve os procedimentos de validação quanto de pré-processamento
modelagem = setup(data = dados,
                  target = 'pagador',
                  train_size = 0.75,
                  normalize = True,
                  ignore_low_variance = True,
                  combine_rare_levels = True,
                  remove_multicollinearity = True,
                  feature_selection = True,
                  fold_strategy = 'stratifiedkfold',
                  fold = 10)
#dados;variável que quero prever; tamanho pra treino; normalização; ignorar as que tem pouca variança
#categorias que tem poucas combinar; mulltipla combinação exclui; seleção de variável (selecionar as melhores)
#fold estratégia: pegar um tanto parecido de casos bons e de casos ruins; fold: terei 10 folds

# Modelos disponiveis
models()

# Analise do modelo Random Forest (Florest Aleatória)
rf = create_model('rf')

# Comparação dentre os modelos do PyCaret
modelos = compare_models()

# Tunagem dos Hiperparâmetros da Floresta 
rf_tunada = tune_model(rf, optimize = 'F1', n_iter = 15)
rf_tunada

# Estimativa do Erro de Generalização do Modelo Final
pred = predict_model(rf_tunada)
pred

# Tornando a variável 'Label' em probabilidades da Classe 1 e calculo de seus quartis
aux1 = 1 - pred[pred['Label'] == 0][['Score']] 
aux2 = pred[pred['Label'] == 1][['Score']] 
probs = pd.concat([aux1, aux2]).sort_index() 
probs.quantile([0.25, 0.5, 0.75]).round(2)